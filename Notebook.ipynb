{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medici&oacute;n y An&aacute;lisis de Reacciones Emocionales a Trav&eacute;s de Estimulos Visuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .imagen-ajustada {\n",
    "        width: 900px;\n",
    "        height: 280px;\n",
    "        border-radius: 20px;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<img src=\"Emociones.jpg\" alt=\"Una imagen\" class=\"imagen-ajustada\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las emociones son algo muy b&aacute;sico en el ser humano, sin embargo muchas veces no es necesario expresar la emoci&oacute;n por medio de palabras, sino que con el rostro se puede denotar lo que estas sintiendo. Basandonos en este concepto el proyecto fue planificado para ver si por medio de estimulos visuales, en este caso videos, se pueden obtener reacciones emocionales de acuerdo a lo que se le muestre.\n",
    "\n",
    "Para el estudio se utilizaron 12 sujetos de prueba, en este caso fueron 8 hombres y 4 mujeres, con un rango de edad de 22 a 56 años con el fin de ver si generaba algun tipo de reaccion emocional por su parte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El estudio consistia en mostrar 7 videos de 30 segundos conformados de la siguiente manera:\n",
    "- Un video de relajacion, con el fin de que el sujeto este en calma.\n",
    "- Un video donde una nina juega con su perro a que es veterinaria, con el fin de tratar de obtener una reaccion de felicidad o gracia. \n",
    "- Un video de relajacion, con el fin de que el sujeto vuelva a un estado neutral.\n",
    "- Un video donde un hombre golpea a su mujer con un bebe en brazos, con el fin de tratar de obtener una reaccion de enojo, impotencia y rabia.\n",
    "- Un video de relajacion, con el fin de que el sujeto vuelva a un estado neutral.\n",
    "- Un video donde una mujer esta abrazando a su perro mientras proceden a dormirlo, con el fin de obtener una reaccion de tristeza.\n",
    "- Finalmente, un video de relajacion con el fin de que el sujeto vuelva a un estado neutral.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fin de comenzar y terminar con un video de relajacion es para ver si hay algun cambio entre el estado inicial y final, como nos indican en la materia de analisis y diseno de experimentos en ciencias de la computacion, tenemos que tener un pre y un post de en el estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias Importadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "import subprocess\n",
    "from moviepy.editor import VideoFileClip\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder comenzar con el tratamiento de los datos fue importante separar los videos de los audios, por lo cual se uso un script para separarlos en distintas carpetas. Despues de eso se trato de cortar los audios a una misma cantidad de tiempo como en el siguiente codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorte completado.\n"
     ]
    }
   ],
   "source": [
    "# Ruta a la carpeta que contiene tus archivos de audio\n",
    "carpeta_audios = './Audios/'\n",
    "\n",
    "# Ruta a la carpeta donde deseas guardar los audios recortados\n",
    "carpeta_destino = './AudiosRecortados/'\n",
    "\n",
    "# Crear la carpeta de destino si no existe\n",
    "if not os.path.exists(carpeta_destino):\n",
    "    os.makedirs(carpeta_destino)\n",
    "\n",
    "# Iterar sobre cada archivo en la carpeta\n",
    "for archivo in os.listdir(carpeta_audios):\n",
    "    ruta_archivo = os.path.join(carpeta_audios, archivo)\n",
    "    \n",
    "    # Cargar el archivo de audio\n",
    "    audio = AudioSegment.from_file(ruta_archivo)\n",
    "    \n",
    "    # Descartar los primeros 30 segundos del audio\n",
    "    audio_recortado = audio[40000:]  # 30 segundos = 30,000 milisegundos\n",
    "    \n",
    "    # Guardar el audio recortado\n",
    "    ruta_destino = os.path.join(carpeta_destino, archivo)\n",
    "    audio_recortado.export(ruta_destino, format=\"wav\")  # Cambia \"wav\" si necesitas otro formato\n",
    "\n",
    "print(\"Recorte completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, no se tomo en cuenta que no todos los audios duraban la misma cantidad de tiempo, asi como las personas hablaban mas o hablaban menos, por lo cual se opto por un script para cortar de forma personalizada cada audio y asi obtener de forma precisa los comentarios de los sujetos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento recortado y guardado.\n"
     ]
    }
   ],
   "source": [
    "# Ruta al archivo de audio específico\n",
    "ruta_audio = './Audios/SUJETO6_TRISTEZA.wav'\n",
    "\n",
    "# Puntos de inicio y fin del segmento en milisegundos\n",
    "# Por ejemplo, para comenzar en el segundo 20 y terminar en el segundo 60\n",
    "inicio_ms = 30000  # Inicio a los 20 segundos\n",
    "duracion_ms = 17000  # Duración de 40 segundos desde el punto de inicio\n",
    "\n",
    "# Cargar el archivo de audio\n",
    "audio = AudioSegment.from_file(ruta_audio)\n",
    "\n",
    "# Recortar el segmento deseado\n",
    "segmento_audio = audio[inicio_ms:inicio_ms+duracion_ms]\n",
    "\n",
    "# Ruta para guardar el segmento recortado\n",
    "ruta_destino = './AudiosRecortados/SUJETO6_TRISTEZA_R.wav'\n",
    "\n",
    "# Guardar el segmento recortado\n",
    "segmento_audio.export(ruta_destino, format=\"wav\")\n",
    "\n",
    "print(\"Segmento recortado y guardado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el siguiente caso fue recortar los videos unicamente cuando se tiene la reaccion del sujeto con el video, por lo cual se utilizo un script para cortar los primeros segundos en base a la duracion del video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ./VideosRecortados/SUJETO10_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO10_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO10_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO10_N4.MOV\n",
      "Moviepy - Building video ./VideosRecortados/SUJETO11_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO11_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO11_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO11_N4.MOV\n",
      "Moviepy - Building video ./VideosRecortados/SUJETO12_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO12_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO12_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO12_N4.MOV\n",
      "Moviepy - Building video ./VideosRecortados/SUJETO1_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO1_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO1_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO1_N4.MOV\n",
      "Moviepy - Building video ./VideosRecortados/SUJETO2_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO2_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO2_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO2_N4.MOV\n",
      "Moviepy - Building video ./VideosRecortados/SUJETO3_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO3_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO3_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO3_N4.MOV\n",
      "Moviepy - Building video ./VideosRecortados/SUJETO4_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO4_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO4_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO4_N4.MOV\n",
      "Moviepy - Building video ./VideosRecortados/SUJETO5_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO5_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO5_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO5_N4.MOV\n",
      "Moviepy - Building video ./VideosRecortados/SUJETO6_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO6_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO6_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO6_N4.MOV\n",
      "Moviepy - Building video ./VideosRecortados/SUJETO7_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO7_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO7_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO7_N4.MOV\n",
      "Moviepy - Building video ./VideosRecortados/SUJETO8_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO8_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO8_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO8_N4.MOV\n",
      "Moviepy - Building video ./VideosRecortados/SUJETO9_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO9_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO9_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO9_N4.MOV\n",
      "Todos los videos han sido recortados y guardados.\n"
     ]
    }
   ],
   "source": [
    "# Define la ruta de la carpeta que contiene los videos originales\n",
    "carpeta_videos = './Videos/'\n",
    "\n",
    "# Define la ruta de la carpeta donde guardarás los videos recortados\n",
    "carpeta_destino = './VideosRecortados/'\n",
    "\n",
    "# Crea la carpeta de destino si no existe\n",
    "if not os.path.exists(carpeta_destino):\n",
    "    os.makedirs(carpeta_destino)\n",
    "\n",
    "# Itera sobre cada archivo en la carpeta de videos\n",
    "for archivo in os.listdir(carpeta_videos):\n",
    "    # Verifica si el archivo termina en '_N1.MOV'\n",
    "    if archivo.endswith('_N4.MOV'):\n",
    "        ruta_completa = os.path.join(carpeta_videos, archivo)\n",
    "        \n",
    "        # Carga el video\n",
    "        video = VideoFileClip(ruta_completa)\n",
    "        \n",
    "        # Recorta el video desde el segundo 0 hasta el segundo 31\n",
    "        video_recortado = video.subclip(0, 33)\n",
    "        \n",
    "        # Define la ruta del archivo de destino\n",
    "        ruta_destino = os.path.join(carpeta_destino, archivo)\n",
    "        \n",
    "        # Guarda el video recortado en la carpeta de destino\n",
    "        video_recortado.write_videofile(ruta_destino, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "        # Cierra el clip para liberar recursos\n",
    "        video.close()\n",
    "        video_recortado.close()\n",
    "\n",
    "print(\"Todos los videos han sido recortados y guardados.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso del participante 9 el internet estaba fallando, por lo cual el video comenzo 8 segundos despues de comenzar a grabar, por lo cual individualmente se recorto el video con el siguiente codigo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ./VideosRecortados/SUJETO9_N4.MOV.\n",
      "MoviePy - Writing audio in SUJETO9_N4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosRecortados/SUJETO9_N4.MOV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosRecortados/SUJETO9_N4.MOV\n",
      "El video SUJETO9_N4.MOV ha sido recortado y guardado.\n"
     ]
    }
   ],
   "source": [
    "# Define la ruta completa al video que deseas recortar\n",
    "ruta_video = './Videos/SUJETO9_N4.MOV'\n",
    "\n",
    "# Define la ruta de la carpeta donde guardarás el video recortado\n",
    "carpeta_destino = './VideosRecortados/'\n",
    "\n",
    "# Crea la carpeta de destino si no existe\n",
    "if not os.path.exists(carpeta_destino):\n",
    "    os.makedirs(carpeta_destino)\n",
    "\n",
    "# Comprueba si el archivo termina en '_N1.MOV'\n",
    "if ruta_video.endswith('_N4.MOV'):\n",
    "    # Carga el video\n",
    "    video = VideoFileClip(ruta_video)\n",
    "    \n",
    "    # Recorta el video desde el segundo 0 hasta el segundo 31\n",
    "    video_recortado = video.subclip(7, 38)\n",
    "    \n",
    "    # Extrae el nombre del archivo del video original\n",
    "    nombre_archivo = os.path.basename(ruta_video)\n",
    "    \n",
    "    # Define la ruta del archivo de destino\n",
    "    ruta_destino = os.path.join(carpeta_destino, nombre_archivo)\n",
    "    \n",
    "    # Guarda el video recortado en la carpeta de destino\n",
    "    video_recortado.write_videofile(ruta_destino, codec=\"libx264\", audio_codec=\"aac\")\n",
    "    \n",
    "    # Cierra el clip para liberar recursos\n",
    "    video.close()\n",
    "    video_recortado.close()\n",
    "\n",
    "    print(f\"El video {nombre_archivo} ha sido recortado y guardado.\")\n",
    "else:\n",
    "    print(\"El archivo no termina en '_N3.MOV', por lo que no se ha recortado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An&aacute;lisis Exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No solo se busco ver que si se obtenian reacciones por medio de estimulos visuales, tambien se aplico un cuestionario donde los sujetos de prueba daban puntuacion dependiendo de cuanto sintieron la emocion del 1 al 5, donde 1 es poco y 5 es mucho.\n",
    "Por lo cual, en base a sus auto reportes se puede ver por medio de la grafica que la mayoria "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# Importa las utilidades de dibujo y los estilos de dibujo de MediaPipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Inicializa FaceMesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "cap = cv2.VideoCapture('./Videos/SUJETO10_ENOJO.MOV')  # Reemplaza esto con la ruta a tu video\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Fin del video o error al cargar el archivo.\")  # Finaliza el bucle si no se pudo leer el video\n",
    "        break\n",
    "    \n",
    "    # Cambia la resolución de la imagen a 640x480\n",
    "    image = cv2.resize(image, (720, 540))\n",
    "\n",
    "    # Convertir la imagen de BGR a RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    \n",
    "    # Detección de puntos de referencia faciales\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "\n",
    "    cv2.imshow('Face Landmark Detection', image)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Presiona ESC para salir\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracci&oacute;n de Caracter&iacute;sticas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  SUJETO INICIO   FIN      LABEL\n",
      "0      SUJETO1_ENOJO.MOV   0:03  0:14      ENOJO\n",
      "1         SUJETO1_N1.MOV   0:10  0:20    NEUTRAL\n",
      "2  SUJETO1_FELICIDAD.MOV   0:07  0:14  FELICIDAD\n",
      "3   SUJETO1_TRISTEZA.MOV   0:03  0:13   TRISTEZA\n",
      "4      SUJETO2_ENOJO.MOV   0:05  0:15      ENOJO\n"
     ]
    }
   ],
   "source": [
    "path = './VideosSegmentados.csv'\n",
    "segmentado_df = pd.read_csv(path)\n",
    "print(segmentado_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ./VideosSegmentados\\SUJETO1_ENOJO_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO1_ENOJO_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO1_ENOJO_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO1_ENOJO_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO1_N1_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO1_N1_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO1_N1_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO1_N1_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO1_FELICIDAD_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO1_FELICIDAD_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO1_FELICIDAD_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO1_FELICIDAD_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO1_TRISTEZA_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO1_TRISTEZA_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO1_TRISTEZA_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO1_TRISTEZA_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO2_ENOJO_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO2_ENOJO_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO2_ENOJO_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO2_ENOJO_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO2_N1_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO2_N1_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO2_N1_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO2_N1_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO2_FELICIDAD_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO2_FELICIDAD_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO2_FELICIDAD_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO2_FELICIDAD_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO2_TRISTEZA_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO2_TRISTEZA_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO2_TRISTEZA_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO2_TRISTEZA_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO3_ENOJO_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO3_ENOJO_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO3_ENOJO_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO3_ENOJO_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO3_N1_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO3_N1_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO3_N1_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO3_N1_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO3_FELICIDAD_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO3_FELICIDAD_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO3_FELICIDAD_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO3_FELICIDAD_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO3_TRISTEZA_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO3_TRISTEZA_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO3_TRISTEZA_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO3_TRISTEZA_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO4_ENOJO_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO4_ENOJO_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO4_ENOJO_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO4_ENOJO_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO4_N1_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO4_N1_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO4_N1_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO4_N1_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO4_FELICIDAD_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO4_FELICIDAD_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO4_FELICIDAD_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO4_FELICIDAD_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO4_TRISTEZA_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO4_TRISTEZA_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO4_TRISTEZA_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO4_TRISTEZA_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO5_ENOJO_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO5_ENOJO_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO5_ENOJO_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO5_ENOJO_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO5_N1_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO5_N1_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO5_N1_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO5_N1_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO5_FELICIDAD_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO5_FELICIDAD_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO5_FELICIDAD_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO5_FELICIDAD_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO5_TRISTEZA_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO5_TRISTEZA_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO5_TRISTEZA_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO5_TRISTEZA_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO6_ENOJO_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO6_ENOJO_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO6_ENOJO_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO6_ENOJO_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO6_N1_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO6_N1_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO6_N1_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO6_N1_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO6_FELICIDAD_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO6_FELICIDAD_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO6_FELICIDAD_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO6_FELICIDAD_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO6_TRISTEZA_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO6_TRISTEZA_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO6_TRISTEZA_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO6_TRISTEZA_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO7_ENOJO_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO7_ENOJO_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO7_ENOJO_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO7_ENOJO_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO7_N1_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO7_N1_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO7_N1_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO7_N1_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO7_FELICIDAD_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO7_FELICIDAD_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO7_FELICIDAD_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO7_FELICIDAD_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO7_TRISTEZA_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO7_TRISTEZA_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO7_TRISTEZA_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO7_TRISTEZA_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO8_ENOJO_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO8_ENOJO_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO8_ENOJO_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO8_ENOJO_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO8_N1_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO8_N1_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO8_N1_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO8_N1_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO8_FELICIDAD_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO8_FELICIDAD_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO8_FELICIDAD_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO8_FELICIDAD_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO8_TRISTEZA_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO8_TRISTEZA_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO8_TRISTEZA_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO8_TRISTEZA_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO9_ENOJO_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO9_ENOJO_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO9_ENOJO_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO9_ENOJO_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO9_N1_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO9_N1_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO9_N1_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO9_N1_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO9_FELICIDAD_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO9_FELICIDAD_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO9_FELICIDAD_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO9_FELICIDAD_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO9_TRISTEZA_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO9_TRISTEZA_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO9_TRISTEZA_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO9_TRISTEZA_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO10_ENOJO_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO10_ENOJO_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO10_ENOJO_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO10_ENOJO_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO10_N1_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO10_N1_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO10_N1_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO10_N1_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO10_FELICIDAD_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO10_FELICIDAD_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO10_FELICIDAD_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO10_FELICIDAD_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO10_TRISTEZA_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO10_TRISTEZA_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO10_TRISTEZA_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO10_TRISTEZA_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO11_ENOJO_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO11_ENOJO_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO11_ENOJO_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO11_ENOJO_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO11_N1_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO11_N1_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO11_N1_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO11_N1_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO11_FELICIDAD_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO11_FELICIDAD_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO11_FELICIDAD_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO11_FELICIDAD_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO11_TRISTEZA_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO11_TRISTEZA_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO11_TRISTEZA_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO11_TRISTEZA_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO12_ENOJO_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO12_ENOJO_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO12_ENOJO_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO12_ENOJO_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO12_N1_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO12_N1_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO12_N1_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO12_N1_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO12_FELICIDAD_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO12_FELICIDAD_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO12_FELICIDAD_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO12_FELICIDAD_segmentado.mp4\n",
      "Moviepy - Building video ./VideosSegmentados\\SUJETO12_TRISTEZA_segmentado.mp4.\n",
      "MoviePy - Writing audio in SUJETO12_TRISTEZA_segmentadoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./VideosSegmentados\\SUJETO12_TRISTEZA_segmentado.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./VideosSegmentados\\SUJETO12_TRISTEZA_segmentado.mp4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "\n",
    "# Cambia esta variable por la ruta a tu archivo CSV\n",
    "csv_file = './VideosSegmentados.csv'\n",
    "\n",
    "# Cambia esta variable por la ruta a la carpeta donde están tus videos originales\n",
    "videos_folder = './Videos/'\n",
    "\n",
    "# Ruta a la carpeta donde quieres guardar los videos segmentados\n",
    "segmented_videos_folder = './VideosSegmentados'\n",
    "\n",
    "# Crea la carpeta para los videos segmentados si no existe\n",
    "if not os.path.exists(segmented_videos_folder):\n",
    "    os.makedirs(segmented_videos_folder)\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Itera sobre cada fila del DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    video_path = os.path.join(videos_folder, row['SUJETO'])\n",
    "    inicio = row['INICIO']\n",
    "    fin = row['FIN']\n",
    "    \n",
    "    # Carga el video\n",
    "    clip = VideoFileClip(video_path)\n",
    "    \n",
    "    # Convierte los tiempos de inicio y fin a segundos\n",
    "    start_seconds = int(inicio.split(':')[0]) * 60 + int(inicio.split(':')[1])\n",
    "    end_seconds = int(fin.split(':')[0]) * 60 + int(fin.split(':')[1])\n",
    "    \n",
    "    # Verifica que el tiempo de inicio y fin estén dentro de la duración del video\n",
    "    if start_seconds >= clip.duration or end_seconds > clip.duration:\n",
    "        print(f\"Error en {video_path}: El tiempo de inicio o fin está fuera de la duración del video.\")\n",
    "        continue  # Salta este video y continúa con el siguiente\n",
    "\n",
    "    # Segmenta el video\n",
    "    new_clip = clip.subclip(start_seconds, end_seconds)\n",
    "    \n",
    "    # Segmenta el video\n",
    "    new_clip = clip.subclip(start_seconds, end_seconds)\n",
    "    \n",
    "    # Define la ruta del nuevo video segmentado, incluyendo la carpeta VideosSegmentados\n",
    "    new_video_filename = os.path.splitext(row['SUJETO'])[0] + '_segmentado.mp4'\n",
    "    new_video_path = os.path.join(segmented_videos_folder, new_video_filename)\n",
    "    \n",
    "    # Escribe el video segmentado en el disco\n",
    "    new_clip.write_videofile(new_video_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "    # Libera recursos\n",
    "    clip.close()\n",
    "    new_clip.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame guardado: SUJETO10_ENOJO_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO10_ENOJO_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO10_ENOJO_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO10_ENOJO_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO10_ENOJO_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO10_ENOJO_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO10_ENOJO_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO10_ENOJO_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO10_ENOJO_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO10_ENOJO_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO10_ENOJO_segmentado_frame300.jpg\n",
      "Frame guardado: SUJETO10_FELICIDAD_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO10_FELICIDAD_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO10_FELICIDAD_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO10_FELICIDAD_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO10_FELICIDAD_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO10_FELICIDAD_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO10_FELICIDAD_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO10_FELICIDAD_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO10_FELICIDAD_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO10_FELICIDAD_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO10_N1_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO10_N1_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO10_N1_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO10_N1_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO10_N1_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO10_N1_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO10_N1_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO10_N1_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO10_N1_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO10_N1_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO10_TRISTEZA_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO10_TRISTEZA_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO10_TRISTEZA_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO10_TRISTEZA_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO10_TRISTEZA_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO10_TRISTEZA_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO10_TRISTEZA_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO10_TRISTEZA_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO10_TRISTEZA_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO10_TRISTEZA_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO11_ENOJO_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO11_ENOJO_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO11_ENOJO_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO11_ENOJO_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO11_ENOJO_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO11_ENOJO_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO11_ENOJO_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO11_ENOJO_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO11_ENOJO_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO11_ENOJO_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO11_ENOJO_segmentado_frame300.jpg\n",
      "Frame guardado: SUJETO11_ENOJO_segmentado_frame330.jpg\n",
      "Frame guardado: SUJETO11_FELICIDAD_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO11_FELICIDAD_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO11_FELICIDAD_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO11_FELICIDAD_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO11_FELICIDAD_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO11_FELICIDAD_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO11_FELICIDAD_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO11_N1_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO11_N1_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO11_N1_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO11_N1_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO11_N1_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO11_N1_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO11_N1_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO11_N1_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO11_N1_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO11_N1_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO11_TRISTEZA_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO11_TRISTEZA_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO11_TRISTEZA_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO11_TRISTEZA_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO11_TRISTEZA_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO11_TRISTEZA_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO11_TRISTEZA_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO11_TRISTEZA_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO11_TRISTEZA_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO11_TRISTEZA_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO12_ENOJO_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO12_ENOJO_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO12_ENOJO_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO12_ENOJO_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO12_ENOJO_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO12_ENOJO_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO12_ENOJO_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO12_ENOJO_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO12_ENOJO_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO12_ENOJO_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO12_FELICIDAD_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO12_FELICIDAD_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO12_FELICIDAD_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO12_FELICIDAD_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO12_FELICIDAD_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO12_FELICIDAD_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO12_FELICIDAD_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO12_FELICIDAD_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO12_FELICIDAD_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO12_FELICIDAD_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO12_N1_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO12_N1_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO12_N1_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO12_N1_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO12_N1_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO12_N1_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO12_N1_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO12_N1_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO12_N1_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO12_N1_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO12_TRISTEZA_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO12_TRISTEZA_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO12_TRISTEZA_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO12_TRISTEZA_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO12_TRISTEZA_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO12_TRISTEZA_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO12_TRISTEZA_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO12_TRISTEZA_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO12_TRISTEZA_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO12_TRISTEZA_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO1_ENOJO_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO1_ENOJO_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO1_ENOJO_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO1_ENOJO_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO1_ENOJO_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO1_ENOJO_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO1_ENOJO_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO1_ENOJO_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO1_ENOJO_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO1_ENOJO_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO1_ENOJO_segmentado_frame300.jpg\n",
      "Frame guardado: SUJETO1_FELICIDAD_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO1_FELICIDAD_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO1_FELICIDAD_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO1_FELICIDAD_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO1_FELICIDAD_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO1_FELICIDAD_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO1_FELICIDAD_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO1_N1_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO1_N1_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO1_N1_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO1_N1_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO1_N1_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO1_N1_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO1_N1_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO1_N1_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO1_N1_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO1_N1_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO1_TRISTEZA_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO1_TRISTEZA_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO1_TRISTEZA_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO1_TRISTEZA_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO1_TRISTEZA_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO1_TRISTEZA_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO1_TRISTEZA_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO1_TRISTEZA_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO1_TRISTEZA_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO1_TRISTEZA_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO2_ENOJO_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO2_ENOJO_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO2_ENOJO_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO2_ENOJO_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO2_ENOJO_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO2_ENOJO_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO2_ENOJO_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO2_ENOJO_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO2_ENOJO_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO2_ENOJO_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO2_FELICIDAD_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO2_FELICIDAD_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO2_FELICIDAD_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO2_FELICIDAD_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO2_FELICIDAD_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO2_FELICIDAD_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO2_FELICIDAD_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO2_FELICIDAD_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO2_FELICIDAD_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO2_N1_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO2_N1_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO2_N1_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO2_N1_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO2_N1_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO2_N1_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO2_N1_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO2_N1_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO2_N1_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO2_N1_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO2_TRISTEZA_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO2_TRISTEZA_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO2_TRISTEZA_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO2_TRISTEZA_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO2_TRISTEZA_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO2_TRISTEZA_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO2_TRISTEZA_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO2_TRISTEZA_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO2_TRISTEZA_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO2_TRISTEZA_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO3_ENOJO_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO3_ENOJO_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO3_ENOJO_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO3_ENOJO_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO3_ENOJO_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO3_ENOJO_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO3_ENOJO_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO3_ENOJO_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO3_ENOJO_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO3_ENOJO_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO3_FELICIDAD_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO3_FELICIDAD_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO3_FELICIDAD_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO3_FELICIDAD_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO3_FELICIDAD_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO3_FELICIDAD_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO3_FELICIDAD_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO3_FELICIDAD_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO3_FELICIDAD_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO3_N1_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO3_N1_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO3_N1_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO3_N1_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO3_N1_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO3_N1_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO3_N1_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO3_N1_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO3_N1_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO3_N1_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO3_TRISTEZA_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO3_TRISTEZA_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO3_TRISTEZA_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO3_TRISTEZA_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO3_TRISTEZA_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO3_TRISTEZA_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO3_TRISTEZA_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO3_TRISTEZA_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO3_TRISTEZA_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO3_TRISTEZA_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO4_ENOJO_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO4_ENOJO_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO4_ENOJO_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO4_ENOJO_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO4_ENOJO_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO4_ENOJO_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO4_ENOJO_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO4_ENOJO_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO4_ENOJO_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO4_ENOJO_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO4_ENOJO_segmentado_frame300.jpg\n",
      "Frame guardado: SUJETO4_FELICIDAD_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO4_FELICIDAD_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO4_FELICIDAD_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO4_FELICIDAD_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO4_FELICIDAD_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO4_FELICIDAD_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO4_FELICIDAD_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO4_FELICIDAD_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO4_FELICIDAD_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO4_N1_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO4_N1_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO4_N1_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO4_N1_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO4_N1_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO4_N1_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO4_N1_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO4_N1_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO4_N1_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO4_N1_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO4_TRISTEZA_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO4_TRISTEZA_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO4_TRISTEZA_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO4_TRISTEZA_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO4_TRISTEZA_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO4_TRISTEZA_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO4_TRISTEZA_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO4_TRISTEZA_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO4_TRISTEZA_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO4_TRISTEZA_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO5_ENOJO_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO5_ENOJO_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO5_ENOJO_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO5_ENOJO_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO5_ENOJO_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO5_ENOJO_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO5_ENOJO_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO5_ENOJO_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO5_ENOJO_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO5_ENOJO_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO5_ENOJO_segmentado_frame300.jpg\n",
      "Frame guardado: SUJETO5_FELICIDAD_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO5_FELICIDAD_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO5_FELICIDAD_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO5_FELICIDAD_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO5_FELICIDAD_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO5_FELICIDAD_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO5_FELICIDAD_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO5_FELICIDAD_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO5_FELICIDAD_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO5_FELICIDAD_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO5_N1_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO5_N1_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO5_N1_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO5_N1_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO5_N1_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO5_N1_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO5_N1_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO5_N1_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO5_N1_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO5_N1_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO5_TRISTEZA_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO5_TRISTEZA_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO5_TRISTEZA_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO5_TRISTEZA_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO5_TRISTEZA_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO5_TRISTEZA_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO5_TRISTEZA_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO5_TRISTEZA_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO5_TRISTEZA_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO6_ENOJO_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO6_ENOJO_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO6_ENOJO_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO6_ENOJO_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO6_ENOJO_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO6_ENOJO_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO6_ENOJO_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO6_ENOJO_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO6_ENOJO_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO6_ENOJO_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO6_ENOJO_segmentado_frame300.jpg\n",
      "Frame guardado: SUJETO6_ENOJO_segmentado_frame330.jpg\n",
      "Frame guardado: SUJETO6_FELICIDAD_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO6_FELICIDAD_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO6_FELICIDAD_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO6_FELICIDAD_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO6_FELICIDAD_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO6_FELICIDAD_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO6_FELICIDAD_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO6_FELICIDAD_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO6_FELICIDAD_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO6_FELICIDAD_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO6_N1_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO6_N1_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO6_N1_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO6_N1_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO6_N1_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO6_N1_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO6_N1_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO6_N1_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO6_N1_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO6_N1_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO6_TRISTEZA_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO6_TRISTEZA_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO6_TRISTEZA_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO6_TRISTEZA_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO6_TRISTEZA_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO7_ENOJO_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO7_ENOJO_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO7_ENOJO_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO7_ENOJO_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO7_ENOJO_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO7_ENOJO_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO7_ENOJO_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO7_ENOJO_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO7_ENOJO_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO7_ENOJO_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO7_ENOJO_segmentado_frame300.jpg\n",
      "Frame guardado: SUJETO7_FELICIDAD_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO7_FELICIDAD_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO7_FELICIDAD_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO7_FELICIDAD_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO7_FELICIDAD_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO7_N1_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO7_N1_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO7_N1_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO7_N1_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO7_N1_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO7_N1_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO7_N1_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO7_N1_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO7_N1_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO7_N1_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO7_TRISTEZA_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO7_TRISTEZA_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO7_TRISTEZA_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO7_TRISTEZA_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO7_TRISTEZA_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO7_TRISTEZA_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO7_TRISTEZA_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO7_TRISTEZA_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO7_TRISTEZA_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO7_TRISTEZA_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO8_ENOJO_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO8_ENOJO_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO8_ENOJO_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO8_ENOJO_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO8_ENOJO_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO8_ENOJO_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO8_ENOJO_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO8_ENOJO_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO8_ENOJO_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO8_ENOJO_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO8_ENOJO_segmentado_frame300.jpg\n",
      "Frame guardado: SUJETO8_ENOJO_segmentado_frame330.jpg\n",
      "Frame guardado: SUJETO8_FELICIDAD_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO8_FELICIDAD_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO8_FELICIDAD_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO8_FELICIDAD_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO8_FELICIDAD_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO8_FELICIDAD_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO8_FELICIDAD_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO8_FELICIDAD_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO8_FELICIDAD_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO8_FELICIDAD_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO8_N1_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO8_N1_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO8_N1_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO8_N1_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO8_N1_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO8_N1_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO8_N1_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO8_N1_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO8_N1_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO8_N1_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO8_TRISTEZA_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO8_TRISTEZA_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO8_TRISTEZA_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO8_TRISTEZA_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO8_TRISTEZA_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO8_TRISTEZA_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO8_TRISTEZA_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO8_TRISTEZA_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO8_TRISTEZA_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO8_TRISTEZA_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO9_ENOJO_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO9_ENOJO_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO9_ENOJO_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO9_ENOJO_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO9_ENOJO_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO9_ENOJO_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO9_ENOJO_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO9_ENOJO_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO9_ENOJO_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO9_ENOJO_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO9_ENOJO_segmentado_frame300.jpg\n",
      "Frame guardado: SUJETO9_ENOJO_segmentado_frame330.jpg\n",
      "Frame guardado: SUJETO9_FELICIDAD_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO9_FELICIDAD_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO9_FELICIDAD_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO9_FELICIDAD_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO9_FELICIDAD_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO9_FELICIDAD_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO9_FELICIDAD_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO9_FELICIDAD_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO9_FELICIDAD_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO9_FELICIDAD_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO9_N1_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO9_N1_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO9_N1_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO9_N1_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO9_N1_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO9_N1_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO9_N1_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO9_N1_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO9_N1_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO9_N1_segmentado_frame270.jpg\n",
      "Frame guardado: SUJETO9_TRISTEZA_segmentado_frame0.jpg\n",
      "Frame guardado: SUJETO9_TRISTEZA_segmentado_frame30.jpg\n",
      "Frame guardado: SUJETO9_TRISTEZA_segmentado_frame60.jpg\n",
      "Frame guardado: SUJETO9_TRISTEZA_segmentado_frame90.jpg\n",
      "Frame guardado: SUJETO9_TRISTEZA_segmentado_frame120.jpg\n",
      "Frame guardado: SUJETO9_TRISTEZA_segmentado_frame150.jpg\n",
      "Frame guardado: SUJETO9_TRISTEZA_segmentado_frame180.jpg\n",
      "Frame guardado: SUJETO9_TRISTEZA_segmentado_frame210.jpg\n",
      "Frame guardado: SUJETO9_TRISTEZA_segmentado_frame240.jpg\n",
      "Frame guardado: SUJETO9_TRISTEZA_segmentado_frame270.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Ruta a la carpeta que contiene los videos\n",
    "videos_folder = './VideosSegmentados/'\n",
    "\n",
    "# Ruta a la carpeta donde se guardarán las imágenes\n",
    "images_folder = './Imagenes/'\n",
    "\n",
    "# Crea la carpeta para las imágenes si no existe\n",
    "if not os.path.exists(images_folder):\n",
    "    os.makedirs(images_folder)\n",
    "\n",
    "# Recorre todos los archivos en la carpeta de videos\n",
    "for video_file in os.listdir(videos_folder):\n",
    "    video_path = os.path.join(videos_folder, video_file)\n",
    "    \n",
    "    # Verifica si el archivo es un video abriéndolo con OpenCV\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"No se pudo abrir el video {video_file}\")\n",
    "        continue\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Extrae un frame cada 30 frames\n",
    "        if frame_count % 30 == 0:\n",
    "            frame_filename = f\"{os.path.splitext(video_file)[0]}_frame{frame_count}.jpg\"\n",
    "            frame_path = os.path.join(images_folder, frame_filename)\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            print(f\"Frame guardado: {frame_filename}\")\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Libera el objeto cap y cierra todas las ventanas de OpenCV\n",
    "    cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Inicializa mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Configuración de FaceMesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "# Ruta a la carpeta de imágenes\n",
    "images_folder = './Imagenes/'\n",
    "\n",
    "# DataFrame para almacenar los keypoints\n",
    "df_keypoints = pd.DataFrame()\n",
    "\n",
    "# Recorre todas las imágenes en la carpeta\n",
    "for image_file in os.listdir(images_folder):\n",
    "    image_path = os.path.join(images_folder, image_file)\n",
    "    \n",
    "    # Lee la imagen\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Verifica si la imagen se cargó correctamente\n",
    "    if image is None:\n",
    "        print(f\"No se pudo cargar la imagen {image_file}\")\n",
    "        continue\n",
    "\n",
    "    # Cambia la resolución de la imagen a 720x540\n",
    "    image = cv2.resize(image, (720, 540))\n",
    "\n",
    "    # Convertir la imagen de BGR a RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Procesa la imagen para detectar los landmarks faciales\n",
    "    results = face_mesh.process(image_rgb)\n",
    "\n",
    "    # Si se encuentran landmarks faciales, extrae la información\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Extrae los keypoints de cada landmark facial\n",
    "            keypoints = []\n",
    "            for landmark in face_landmarks.landmark:\n",
    "                keypoints.append({\n",
    "                    'x': landmark.x,\n",
    "                    'y': landmark.y,\n",
    "                    'z': landmark.z\n",
    "                })\n",
    "            # Añade los keypoints al DataFrame\n",
    "            df_image_keypoints = pd.DataFrame(keypoints)\n",
    "            df_image_keypoints['image'] = image_file\n",
    "            df_keypoints = pd.concat([df_keypoints, df_image_keypoints], ignore_index=True)\n",
    "\n",
    "# Cierra FaceMesh\n",
    "face_mesh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.514819</td>\n",
       "      <td>0.862191</td>\n",
       "      <td>-0.031919</td>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.521086</td>\n",
       "      <td>0.776935</td>\n",
       "      <td>-0.065382</td>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.518349</td>\n",
       "      <td>0.793673</td>\n",
       "      <td>-0.033238</td>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.517264</td>\n",
       "      <td>0.708311</td>\n",
       "      <td>-0.052481</td>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.523252</td>\n",
       "      <td>0.757754</td>\n",
       "      <td>-0.070094</td>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223699</th>\n",
       "      <td>0.541657</td>\n",
       "      <td>0.608421</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame90.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223700</th>\n",
       "      <td>0.554624</td>\n",
       "      <td>0.611048</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame90.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223701</th>\n",
       "      <td>0.543330</td>\n",
       "      <td>0.592531</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame90.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223702</th>\n",
       "      <td>0.528629</td>\n",
       "      <td>0.605639</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame90.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223703</th>\n",
       "      <td>0.539915</td>\n",
       "      <td>0.624362</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame90.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223704 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x         y         z                                    image\n",
       "0       0.514819  0.862191 -0.031919     SUJETO10_ENOJO_segmentado_frame0.jpg\n",
       "1       0.521086  0.776935 -0.065382     SUJETO10_ENOJO_segmentado_frame0.jpg\n",
       "2       0.518349  0.793673 -0.033238     SUJETO10_ENOJO_segmentado_frame0.jpg\n",
       "3       0.517264  0.708311 -0.052481     SUJETO10_ENOJO_segmentado_frame0.jpg\n",
       "4       0.523252  0.757754 -0.070094     SUJETO10_ENOJO_segmentado_frame0.jpg\n",
       "...          ...       ...       ...                                      ...\n",
       "223699  0.541657  0.608421  0.009365  SUJETO9_TRISTEZA_segmentado_frame90.jpg\n",
       "223700  0.554624  0.611048  0.009365  SUJETO9_TRISTEZA_segmentado_frame90.jpg\n",
       "223701  0.543330  0.592531  0.009365  SUJETO9_TRISTEZA_segmentado_frame90.jpg\n",
       "223702  0.528629  0.605639  0.009365  SUJETO9_TRISTEZA_segmentado_frame90.jpg\n",
       "223703  0.539915  0.624362  0.009365  SUJETO9_TRISTEZA_segmentado_frame90.jpg\n",
       "\n",
       "[223704 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda el DataFrame en un archivo CSV si es necesario\n",
    "df_keypoints.to_csv('facemesh_keypoints.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16476\\1941483712.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mkeypoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'keypointX_{i}'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlandmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mkeypoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'keypointY_{i}'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlandmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;31m# Añade los keypoints aplanados al DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[0mdf_keypoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_keypoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeypoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m# Guarda el DataFrame en un archivo CSV si es necesario\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;31m#df_keypoints.to_csv('facemesh_keypoints_flattened.csv', index=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ages0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6293\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6294\u001b[0m         ):\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6296\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Inicializa mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Configuración de FaceMesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "# Ruta a la carpeta de imágenes\n",
    "images_folder = './Imagenes'\n",
    "\n",
    "# DataFrame para almacenar los keypoints\n",
    "df_keypoints = pd.DataFrame()\n",
    "\n",
    "# Recorre todas las imágenes en la carpeta\n",
    "for image_file in os.listdir(images_folder):\n",
    "    image_path = os.path.join(images_folder, image_file)\n",
    "    \n",
    "    # Lee la imagen\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Verifica si la imagen se cargó correctamente\n",
    "    if image is None:\n",
    "        print(f\"No se pudo cargar la imagen {image_file}\")\n",
    "        continue\n",
    "\n",
    "    # Cambia la resolución de la imagen a 720x540\n",
    "    image = cv2.resize(image, (720, 540))\n",
    "\n",
    "    # Convertir la imagen de BGR a RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Procesa la imagen para detectar los landmarks faciales\n",
    "    results = face_mesh.process(image_rgb)\n",
    "\n",
    "    # Si se encuentran landmarks faciales, extrae la información\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Aplanar los keypoints para una sola fila\n",
    "            keypoints = {'label': 'inserta_tu_label_aquí'}\n",
    "            for i, landmark in enumerate(face_landmarks.landmark):\n",
    "                keypoints[f'keypointX_{i}'] = landmark.x\n",
    "                keypoints[f'keypointY_{i}'] = landmark.y\n",
    "\n",
    "            # Añade los keypoints aplanados al DataFrame\n",
    "            df_keypoints = df_keypoints.append(keypoints, ignore_index=True)\n",
    "\n",
    "# Guarda el DataFrame en un archivo CSV si es necesario\n",
    "#df_keypoints.to_csv('facemesh_keypoints_flattened.csv', index=False)\n",
    "\n",
    "# Cierra FaceMesh\n",
    "face_mesh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m         temp_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([landmark_dict])\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;66;03m# Concatenar el DataFrame temporal con el DataFrame principal\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m         landmarks_filter_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlandmarks_filter_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_df\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\ages0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ages0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Users\\ages0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:149\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m             nb \u001b[38;5;241m=\u001b[39m _concat_homogeneous_fastpath(mgrs_indexers, shape, first_dtype)\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m BlockManager((nb,), axes)\n\u001b[1;32m--> 149\u001b[0m mgrs \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_reindex_columns_na_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mgrs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    152\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m mgrs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ages0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:220\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[1;34m(axes, mgrs_indexers, needs_copy)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mgr, indexers \u001b[38;5;129;01min\u001b[39;00m mgrs_indexers:\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# For axis=0 (i.e. columns) we use_na_proxy and only_slice, so this\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m#  is a cheap reindexing.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, indexer \u001b[38;5;129;01min\u001b[39;00m indexers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 220\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m            \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# only relevant for i==0\u001b[39;49;00m\n\u001b[0;32m    226\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# only relevant for i==0\u001b[39;49;00m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m needs_copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexers:\n\u001b[0;32m    230\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\ages0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:680\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    689\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\ages0\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:838\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, ml \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(taker, mgr_locs):\n\u001b[0;32m    837\u001b[0m     slc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 838\u001b[0m     bp \u001b[38;5;241m=\u001b[39m \u001b[43mBlockPlacement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m     nb \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mgetitem_block_columns(slc, new_mgr_locs\u001b[38;5;241m=\u001b[39mbp)\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;66;03m# We have np.shares_memory(nb.values, blk.values)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Definir la función para extraer landmarks faciales de un fotograma\n",
    "def extract_landmarks(frame):\n",
    "    # Inicializar MediaPipe Face Mesh cada vez que se llama a la función\n",
    "    with mp.solutions.face_mesh.FaceMesh(\n",
    "        static_image_mode=True,\n",
    "        max_num_faces=1,\n",
    "        min_detection_confidence=0.5) as face_mesh:\n",
    "\n",
    "        # Convertir la imagen a RGB\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Procesar la imagen y obtener los resultados de los landmarks faciales\n",
    "        results = face_mesh.process(image_rgb)\n",
    "        \n",
    "        # Verificar si se detectaron landmarks faciales\n",
    "        if results.multi_face_landmarks:\n",
    "            # Obtener los landmarks faciales del primer rostro detectado\n",
    "            face_landmarks = results.multi_face_landmarks[0]\n",
    "            \n",
    "            # Convertir los landmarks a una lista de tuplas de coordenadas (x, y, z)\n",
    "            landmarks = [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark]\n",
    "            \n",
    "            return landmarks  # Devolver la lista de landmarks faciales\n",
    "\n",
    "    return None\n",
    "\n",
    "path = \"./Videos/\"\n",
    "list_dir = os.listdir(path)\n",
    "df_all_data_landmarks = pd.DataFrame(columns=['Video', 'Frame', 'Landmarks'])  # Asegúrate de usar el nombre correcto de DataFrame aquí\n",
    "landmarks_filter_data = pd.DataFrame(columns=['filename'] + [f\"x_{i}\" for i in range(468)] + [f\"y_{i}\" for i in range(468)] + [f\"z_{i}\" for i in range(468)] + ['label'])\n",
    "\n",
    "for file in list_dir:\n",
    "    cap = cv2.VideoCapture(path + file)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error al abrir el video: {file}\")\n",
    "        continue\n",
    "\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        landmarks = extract_landmarks(frame)\n",
    "        \n",
    "        if landmarks:\n",
    "            landmark_dict = {\"filename\": file}\n",
    "            for i, lm in enumerate(landmarks):\n",
    "                landmark_dict[f\"x_{i}\"] = lm[0]\n",
    "                landmark_dict[f\"y_{i}\"] = lm[1]\n",
    "                landmark_dict[f\"z_{i}\"] = lm[2]\n",
    "\n",
    "            label = file.split('_')[1]\n",
    "            landmark_dict['label'] = label\n",
    "\n",
    "            # Crear un DataFrame temporal con los datos de esta fila\n",
    "            temp_df = pd.DataFrame([landmark_dict])\n",
    "\n",
    "            # Concatenar el DataFrame temporal con el DataFrame principal\n",
    "            landmarks_filter_data = pd.concat([landmarks_filter_data, temp_df], ignore_index=True)\n",
    "\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_data_landmarks = landmarks_data\n",
    "# Guardar el DataFrame con los landmarks de todos los videos como un archivo CSV\n",
    "df_all_data_landmarks.to_csv('df_all_data_landmarks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Video  Landmark_ID         x         y         z\n",
      "0  SUJETO10_N1.MOV            0  0.535982  0.731780 -0.037235\n",
      "1  SUJETO10_N1.MOV            1  0.538623  0.643297 -0.072559\n",
      "2  SUJETO10_N1.MOV            2  0.535853  0.665372 -0.038538\n",
      "3  SUJETO10_N1.MOV            3  0.532896  0.566527 -0.055616\n",
      "4  SUJETO10_N1.MOV            4  0.540620  0.620441 -0.077139\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Inicializa MediaPipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# Lista para almacenar los datos de los landmarks\n",
    "landmarks_data = []\n",
    "\n",
    "# Carpeta que contiene los videos\n",
    "videos_folder = './Videos/'\n",
    "\n",
    "# Lista todos los archivos en la carpeta que terminan con _N1.MOV\n",
    "video_files = [f for f in os.listdir(videos_folder) if f.endswith('_N1.MOV')]\n",
    "\n",
    "# Procesa cada video que cumple con el criterio\n",
    "for video_file in video_files:\n",
    "    video_path = os.path.join(videos_folder, video_file)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                break  # Fin del video\n",
    "\n",
    "            # Preprocesa la imagen\n",
    "            image = cv2.resize(image, (720, 540))\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = face_mesh.process(image_rgb)\n",
    "\n",
    "            # Extrae landmarks faciales si están disponibles\n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    # Extrae landmarks y los almacena en la lista\n",
    "                    for idx, landmark in enumerate(face_landmarks.landmark):\n",
    "                        landmarks_data.append({\n",
    "                            'Video': video_file,\n",
    "                            'Landmark_ID': idx,\n",
    "                            'x': landmark.x,\n",
    "                            'y': landmark.y,\n",
    "                            'z': landmark.z\n",
    "                        })\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Crea un DataFrame a partir de la lista de datos\n",
    "df_all_videos_landmarks = pd.DataFrame(landmarks_data)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Muestra los primeros registros del DataFrame\n",
    "print(df_all_videos_landmarks.head())\n",
    "\n",
    "# Opcional: Guarda el DataFrame a un archivo CSV\n",
    "# df_all_videos_landmarks.to_csv('video_landmarks_N1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K1X</th>\n",
       "      <th>K2X</th>\n",
       "      <th>K3X</th>\n",
       "      <th>K4X</th>\n",
       "      <th>K5X</th>\n",
       "      <th>K6X</th>\n",
       "      <th>K7X</th>\n",
       "      <th>K8X</th>\n",
       "      <th>K9X</th>\n",
       "      <th>K10X</th>\n",
       "      <th>...</th>\n",
       "      <th>K459Y</th>\n",
       "      <th>K460Y</th>\n",
       "      <th>K461Y</th>\n",
       "      <th>K462Y</th>\n",
       "      <th>K463Y</th>\n",
       "      <th>K464Y</th>\n",
       "      <th>K465Y</th>\n",
       "      <th>K466Y</th>\n",
       "      <th>K467Y</th>\n",
       "      <th>K468Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 936 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [K1X, K2X, K3X, K4X, K5X, K6X, K7X, K8X, K9X, K10X, K11X, K12X, K13X, K14X, K15X, K16X, K17X, K18X, K19X, K20X, K21X, K22X, K23X, K24X, K25X, K26X, K27X, K28X, K29X, K30X, K31X, K32X, K33X, K34X, K35X, K36X, K37X, K38X, K39X, K40X, K41X, K42X, K43X, K44X, K45X, K46X, K47X, K48X, K49X, K50X, K51X, K52X, K53X, K54X, K55X, K56X, K57X, K58X, K59X, K60X, K61X, K62X, K63X, K64X, K65X, K66X, K67X, K68X, K69X, K70X, K71X, K72X, K73X, K74X, K75X, K76X, K77X, K78X, K79X, K80X, K81X, K82X, K83X, K84X, K85X, K86X, K87X, K88X, K89X, K90X, K91X, K92X, K93X, K94X, K95X, K96X, K97X, K98X, K99X, K100X, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 936 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Image       K1X       K1Y       K2X  \\\n",
      "0    SUJETO10_ENOJO_segmentado_frame0.jpg  0.516717  0.862611  0.525122   \n",
      "1  SUJETO10_ENOJO_segmentado_frame120.jpg  0.522165  0.873315  0.534889   \n",
      "2  SUJETO10_ENOJO_segmentado_frame150.jpg  0.521257  0.869050  0.532735   \n",
      "3  SUJETO10_ENOJO_segmentado_frame180.jpg  0.519951  0.869113  0.532665   \n",
      "4  SUJETO10_ENOJO_segmentado_frame210.jpg  0.522861  0.869178  0.534696   \n",
      "\n",
      "        K2Y       K3X       K3Y       K4X       K4Y       K5X  ...     K474X  \\\n",
      "0  0.781059  0.522194  0.800093  0.520307  0.707113  0.527029  ...  0.586153   \n",
      "1  0.798453  0.530828  0.816012  0.530545  0.722064  0.537171  ...  0.594279   \n",
      "2  0.793808  0.528710  0.811547  0.528189  0.717880  0.534973  ...  0.593558   \n",
      "3  0.793192  0.528782  0.810866  0.527933  0.718591  0.534852  ...  0.592393   \n",
      "4  0.794747  0.530758  0.812396  0.530206  0.719392  0.536961  ...  0.594907   \n",
      "\n",
      "      K474Y     K475X     K475Y     K476X     K476Y     K477X     K477Y  \\\n",
      "0  0.654642  0.597166  0.657380  0.587159  0.638631  0.575269  0.651748   \n",
      "1  0.667019  0.605121  0.669919  0.595619  0.650519  0.583513  0.663937   \n",
      "2  0.667484  0.604407  0.670765  0.594810  0.650166  0.582683  0.663929   \n",
      "3  0.671306  0.602347  0.674140  0.593610  0.656219  0.582534  0.668459   \n",
      "4  0.669738  0.605531  0.672815  0.596163  0.653849  0.584328  0.666554   \n",
      "\n",
      "      K478X     K478Y  \n",
      "0  0.585243  0.670582  \n",
      "1  0.593000  0.683557  \n",
      "2  0.592320  0.684695  \n",
      "3  0.591239  0.686257  \n",
      "4  0.593704  0.685507  \n",
      "\n",
      "[5 rows x 957 columns]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Inicializa MediaPipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Lista para almacenar los datos de los landmarks\n",
    "landmarks_data = []\n",
    "\n",
    "# Carpeta que contiene las imágenes\n",
    "images_folder = './Imagenes'\n",
    "\n",
    "# Inicializa FaceMesh con las opciones deseadas\n",
    "with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    # Lista todos los archivos en la carpeta de imágenes\n",
    "    image_files = [f for f in os.listdir(images_folder) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    # Procesa cada imagen que cumple con el criterio\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(images_folder, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Verifica si la imagen se cargó correctamente\n",
    "        if image is None:\n",
    "            print(f\"No se pudo cargar la imagen {image_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Cambia la resolución de la imagen y la convierte a RGB\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Procesa la imagen para obtener los landmarks\n",
    "        results = face_mesh.process(image_rgb)\n",
    "        \n",
    "        # Extrae landmarks faciales si están disponibles\n",
    "        if results.multi_face_landmarks:\n",
    "            # Cada imagen dará lugar a una sola fila con todos los landmarks\n",
    "            row = {'Image': image_file}\n",
    "            for landmark_id, landmark in enumerate(results.multi_face_landmarks[0].landmark):\n",
    "                # Añade las coordenadas x, y de cada landmark al diccionario de la fila\n",
    "                row[f'K{landmark_id + 1}X'] = landmark.x\n",
    "                row[f'K{landmark_id + 1}Y'] = landmark.y\n",
    "            \n",
    "            landmarks_data.append(row)\n",
    "\n",
    "# Crea un DataFrame a partir de la lista de datos\n",
    "df_flat_landmarks = pd.DataFrame(landmarks_data)\n",
    "\n",
    "# Muestra los primeros registros del DataFrame\n",
    "print(df_flat_landmarks.head())\n",
    "\n",
    "# Opcional: Guarda el DataFrame a un archivo CSV\n",
    "# df_flat_landmarks.to_csv('flat_landmarks_images.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>K1X</th>\n",
       "      <th>K1Y</th>\n",
       "      <th>K2X</th>\n",
       "      <th>K2Y</th>\n",
       "      <th>K3X</th>\n",
       "      <th>K3Y</th>\n",
       "      <th>K4X</th>\n",
       "      <th>K4Y</th>\n",
       "      <th>K5X</th>\n",
       "      <th>...</th>\n",
       "      <th>K474X</th>\n",
       "      <th>K474Y</th>\n",
       "      <th>K475X</th>\n",
       "      <th>K475Y</th>\n",
       "      <th>K476X</th>\n",
       "      <th>K476Y</th>\n",
       "      <th>K477X</th>\n",
       "      <th>K477Y</th>\n",
       "      <th>K478X</th>\n",
       "      <th>K478Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame0.jpg</td>\n",
       "      <td>0.516717</td>\n",
       "      <td>0.862611</td>\n",
       "      <td>0.525122</td>\n",
       "      <td>0.781059</td>\n",
       "      <td>0.522194</td>\n",
       "      <td>0.800093</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.707113</td>\n",
       "      <td>0.527029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586153</td>\n",
       "      <td>0.654642</td>\n",
       "      <td>0.597166</td>\n",
       "      <td>0.657380</td>\n",
       "      <td>0.587159</td>\n",
       "      <td>0.638631</td>\n",
       "      <td>0.575269</td>\n",
       "      <td>0.651748</td>\n",
       "      <td>0.585243</td>\n",
       "      <td>0.670582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame120.jpg</td>\n",
       "      <td>0.522165</td>\n",
       "      <td>0.873315</td>\n",
       "      <td>0.534889</td>\n",
       "      <td>0.798453</td>\n",
       "      <td>0.530828</td>\n",
       "      <td>0.816012</td>\n",
       "      <td>0.530545</td>\n",
       "      <td>0.722064</td>\n",
       "      <td>0.537171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594279</td>\n",
       "      <td>0.667019</td>\n",
       "      <td>0.605121</td>\n",
       "      <td>0.669919</td>\n",
       "      <td>0.595619</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>0.583513</td>\n",
       "      <td>0.663937</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.683557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame150.jpg</td>\n",
       "      <td>0.521257</td>\n",
       "      <td>0.869050</td>\n",
       "      <td>0.532735</td>\n",
       "      <td>0.793808</td>\n",
       "      <td>0.528710</td>\n",
       "      <td>0.811547</td>\n",
       "      <td>0.528189</td>\n",
       "      <td>0.717880</td>\n",
       "      <td>0.534973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593558</td>\n",
       "      <td>0.667484</td>\n",
       "      <td>0.604407</td>\n",
       "      <td>0.670765</td>\n",
       "      <td>0.594810</td>\n",
       "      <td>0.650166</td>\n",
       "      <td>0.582683</td>\n",
       "      <td>0.663929</td>\n",
       "      <td>0.592320</td>\n",
       "      <td>0.684695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame180.jpg</td>\n",
       "      <td>0.519951</td>\n",
       "      <td>0.869113</td>\n",
       "      <td>0.532665</td>\n",
       "      <td>0.793192</td>\n",
       "      <td>0.528782</td>\n",
       "      <td>0.810866</td>\n",
       "      <td>0.527933</td>\n",
       "      <td>0.718591</td>\n",
       "      <td>0.534852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592393</td>\n",
       "      <td>0.671306</td>\n",
       "      <td>0.602347</td>\n",
       "      <td>0.674140</td>\n",
       "      <td>0.593610</td>\n",
       "      <td>0.656219</td>\n",
       "      <td>0.582534</td>\n",
       "      <td>0.668459</td>\n",
       "      <td>0.591239</td>\n",
       "      <td>0.686257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame210.jpg</td>\n",
       "      <td>0.522861</td>\n",
       "      <td>0.869178</td>\n",
       "      <td>0.534696</td>\n",
       "      <td>0.794747</td>\n",
       "      <td>0.530758</td>\n",
       "      <td>0.812396</td>\n",
       "      <td>0.530206</td>\n",
       "      <td>0.719392</td>\n",
       "      <td>0.536961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594907</td>\n",
       "      <td>0.669738</td>\n",
       "      <td>0.605531</td>\n",
       "      <td>0.672815</td>\n",
       "      <td>0.596163</td>\n",
       "      <td>0.653849</td>\n",
       "      <td>0.584328</td>\n",
       "      <td>0.666554</td>\n",
       "      <td>0.593704</td>\n",
       "      <td>0.685507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame240.jpg</td>\n",
       "      <td>0.453008</td>\n",
       "      <td>0.793498</td>\n",
       "      <td>0.458177</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.456633</td>\n",
       "      <td>0.737436</td>\n",
       "      <td>0.452061</td>\n",
       "      <td>0.642798</td>\n",
       "      <td>0.459526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525427</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.537411</td>\n",
       "      <td>0.605893</td>\n",
       "      <td>0.526688</td>\n",
       "      <td>0.585254</td>\n",
       "      <td>0.513452</td>\n",
       "      <td>0.599915</td>\n",
       "      <td>0.524098</td>\n",
       "      <td>0.620761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame270.jpg</td>\n",
       "      <td>0.455805</td>\n",
       "      <td>0.793401</td>\n",
       "      <td>0.464809</td>\n",
       "      <td>0.713732</td>\n",
       "      <td>0.463130</td>\n",
       "      <td>0.735859</td>\n",
       "      <td>0.458704</td>\n",
       "      <td>0.641522</td>\n",
       "      <td>0.466215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532660</td>\n",
       "      <td>0.605918</td>\n",
       "      <td>0.544063</td>\n",
       "      <td>0.608902</td>\n",
       "      <td>0.533972</td>\n",
       "      <td>0.588991</td>\n",
       "      <td>0.521302</td>\n",
       "      <td>0.602830</td>\n",
       "      <td>0.531304</td>\n",
       "      <td>0.622859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame30.jpg</td>\n",
       "      <td>0.451938</td>\n",
       "      <td>0.797064</td>\n",
       "      <td>0.454748</td>\n",
       "      <td>0.717145</td>\n",
       "      <td>0.453761</td>\n",
       "      <td>0.739351</td>\n",
       "      <td>0.448418</td>\n",
       "      <td>0.644463</td>\n",
       "      <td>0.455899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523657</td>\n",
       "      <td>0.601855</td>\n",
       "      <td>0.535964</td>\n",
       "      <td>0.604622</td>\n",
       "      <td>0.524808</td>\n",
       "      <td>0.583856</td>\n",
       "      <td>0.511326</td>\n",
       "      <td>0.598940</td>\n",
       "      <td>0.522452</td>\n",
       "      <td>0.619921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame60.jpg</td>\n",
       "      <td>0.463313</td>\n",
       "      <td>0.787222</td>\n",
       "      <td>0.469396</td>\n",
       "      <td>0.711167</td>\n",
       "      <td>0.467647</td>\n",
       "      <td>0.732886</td>\n",
       "      <td>0.462881</td>\n",
       "      <td>0.640404</td>\n",
       "      <td>0.470740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535791</td>\n",
       "      <td>0.601218</td>\n",
       "      <td>0.547727</td>\n",
       "      <td>0.604323</td>\n",
       "      <td>0.537343</td>\n",
       "      <td>0.584747</td>\n",
       "      <td>0.523882</td>\n",
       "      <td>0.598001</td>\n",
       "      <td>0.534184</td>\n",
       "      <td>0.617750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame90.jpg</td>\n",
       "      <td>0.466474</td>\n",
       "      <td>0.795463</td>\n",
       "      <td>0.471724</td>\n",
       "      <td>0.722081</td>\n",
       "      <td>0.469866</td>\n",
       "      <td>0.742865</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.650051</td>\n",
       "      <td>0.473138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539010</td>\n",
       "      <td>0.608497</td>\n",
       "      <td>0.550433</td>\n",
       "      <td>0.611247</td>\n",
       "      <td>0.540197</td>\n",
       "      <td>0.591266</td>\n",
       "      <td>0.527597</td>\n",
       "      <td>0.605644</td>\n",
       "      <td>0.537758</td>\n",
       "      <td>0.625812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 957 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Image       K1X       K1Y       K2X  \\\n",
       "0        SUJETO10_ENOJO_segmentado_frame0.jpg  0.516717  0.862611  0.525122   \n",
       "1      SUJETO10_ENOJO_segmentado_frame120.jpg  0.522165  0.873315  0.534889   \n",
       "2      SUJETO10_ENOJO_segmentado_frame150.jpg  0.521257  0.869050  0.532735   \n",
       "3      SUJETO10_ENOJO_segmentado_frame180.jpg  0.519951  0.869113  0.532665   \n",
       "4      SUJETO10_ENOJO_segmentado_frame210.jpg  0.522861  0.869178  0.534696   \n",
       "..                                        ...       ...       ...       ...   \n",
       "464  SUJETO9_TRISTEZA_segmentado_frame240.jpg  0.453008  0.793498  0.458177   \n",
       "465  SUJETO9_TRISTEZA_segmentado_frame270.jpg  0.455805  0.793401  0.464809   \n",
       "466   SUJETO9_TRISTEZA_segmentado_frame30.jpg  0.451938  0.797064  0.454748   \n",
       "467   SUJETO9_TRISTEZA_segmentado_frame60.jpg  0.463313  0.787222  0.469396   \n",
       "468   SUJETO9_TRISTEZA_segmentado_frame90.jpg  0.466474  0.795463  0.471724   \n",
       "\n",
       "          K2Y       K3X       K3Y       K4X       K4Y       K5X  ...  \\\n",
       "0    0.781059  0.522194  0.800093  0.520307  0.707113  0.527029  ...   \n",
       "1    0.798453  0.530828  0.816012  0.530545  0.722064  0.537171  ...   \n",
       "2    0.793808  0.528710  0.811547  0.528189  0.717880  0.534973  ...   \n",
       "3    0.793192  0.528782  0.810866  0.527933  0.718591  0.534852  ...   \n",
       "4    0.794747  0.530758  0.812396  0.530206  0.719392  0.536961  ...   \n",
       "..        ...       ...       ...       ...       ...       ...  ...   \n",
       "464  0.714694  0.456633  0.737436  0.452061  0.642798  0.459526  ...   \n",
       "465  0.713732  0.463130  0.735859  0.458704  0.641522  0.466215  ...   \n",
       "466  0.717145  0.453761  0.739351  0.448418  0.644463  0.455899  ...   \n",
       "467  0.711167  0.467647  0.732886  0.462881  0.640404  0.470740  ...   \n",
       "468  0.722081  0.469866  0.742865  0.465500  0.650051  0.473138  ...   \n",
       "\n",
       "        K474X     K474Y     K475X     K475Y     K476X     K476Y     K477X  \\\n",
       "0    0.586153  0.654642  0.597166  0.657380  0.587159  0.638631  0.575269   \n",
       "1    0.594279  0.667019  0.605121  0.669919  0.595619  0.650519  0.583513   \n",
       "2    0.593558  0.667484  0.604407  0.670765  0.594810  0.650166  0.582683   \n",
       "3    0.592393  0.671306  0.602347  0.674140  0.593610  0.656219  0.582534   \n",
       "4    0.594907  0.669738  0.605531  0.672815  0.596163  0.653849  0.584328   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "464  0.525427  0.602941  0.537411  0.605893  0.526688  0.585254  0.513452   \n",
       "465  0.532660  0.605918  0.544063  0.608902  0.533972  0.588991  0.521302   \n",
       "466  0.523657  0.601855  0.535964  0.604622  0.524808  0.583856  0.511326   \n",
       "467  0.535791  0.601218  0.547727  0.604323  0.537343  0.584747  0.523882   \n",
       "468  0.539010  0.608497  0.550433  0.611247  0.540197  0.591266  0.527597   \n",
       "\n",
       "        K477Y     K478X     K478Y  \n",
       "0    0.651748  0.585243  0.670582  \n",
       "1    0.663937  0.593000  0.683557  \n",
       "2    0.663929  0.592320  0.684695  \n",
       "3    0.668459  0.591239  0.686257  \n",
       "4    0.666554  0.593704  0.685507  \n",
       "..        ...       ...       ...  \n",
       "464  0.599915  0.524098  0.620761  \n",
       "465  0.602830  0.531304  0.622859  \n",
       "466  0.598940  0.522452  0.619921  \n",
       "467  0.598001  0.534184  0.617750  \n",
       "468  0.605644  0.537758  0.625812  \n",
       "\n",
       "[469 rows x 957 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flat_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Image       K1X       K1Y       K2X  \\\n",
      "0    SUJETO10_ENOJO_segmentado_frame0.jpg  0.516717  0.862611  0.525122   \n",
      "1  SUJETO10_ENOJO_segmentado_frame120.jpg  0.522165  0.873315  0.534889   \n",
      "2  SUJETO10_ENOJO_segmentado_frame150.jpg  0.521257  0.869050  0.532735   \n",
      "3  SUJETO10_ENOJO_segmentado_frame180.jpg  0.519951  0.869113  0.532665   \n",
      "4  SUJETO10_ENOJO_segmentado_frame210.jpg  0.522861  0.869178  0.534696   \n",
      "\n",
      "        K2Y       K3X       K3Y       K4X       K4Y       K5X  ...     K474Y  \\\n",
      "0  0.781059  0.522194  0.800093  0.520307  0.707113  0.527029  ...  0.654642   \n",
      "1  0.798453  0.530828  0.816012  0.530545  0.722064  0.537171  ...  0.667019   \n",
      "2  0.793808  0.528710  0.811547  0.528189  0.717880  0.534973  ...  0.667484   \n",
      "3  0.793192  0.528782  0.810866  0.527933  0.718591  0.534852  ...  0.671306   \n",
      "4  0.794747  0.530758  0.812396  0.530206  0.719392  0.536961  ...  0.669738   \n",
      "\n",
      "      K475X     K475Y     K476X     K476Y     K477X     K477Y     K478X  \\\n",
      "0  0.597166  0.657380  0.587159  0.638631  0.575269  0.651748  0.585243   \n",
      "1  0.605121  0.669919  0.595619  0.650519  0.583513  0.663937  0.593000   \n",
      "2  0.604407  0.670765  0.594810  0.650166  0.582683  0.663929  0.592320   \n",
      "3  0.602347  0.674140  0.593610  0.656219  0.582534  0.668459  0.591239   \n",
      "4  0.605531  0.672815  0.596163  0.653849  0.584328  0.666554  0.593704   \n",
      "\n",
      "      K478Y  Label  \n",
      "0  0.670582  ENOJO  \n",
      "1  0.683557  ENOJO  \n",
      "2  0.684695  ENOJO  \n",
      "3  0.686257  ENOJO  \n",
      "4  0.685507  ENOJO  \n",
      "\n",
      "[5 rows x 958 columns]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Inicializa MediaPipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Lista para almacenar los datos de los landmarks\n",
    "landmarks_data = []\n",
    "\n",
    "# Carpeta que contiene las imágenes\n",
    "images_folder = './Imagenes/'\n",
    "\n",
    "# Inicializa FaceMesh con las opciones deseadas\n",
    "with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    # Lista todos los archivos en la carpeta de imágenes\n",
    "    image_files = [f for f in os.listdir(images_folder) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    # Procesa cada imagen que cumple con el criterio\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(images_folder, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Verifica si la imagen se cargó correctamente\n",
    "        if image is None:\n",
    "            print(f\"No se pudo cargar la imagen {image_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Cambia la resolución de la imagen y la convierte a RGB\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Procesa la imagen para obtener los landmarks\n",
    "        results = face_mesh.process(image_rgb)\n",
    "        \n",
    "        # Extrae landmarks faciales si están disponibles\n",
    "        if results.multi_face_landmarks:\n",
    "            # Cada imagen dará lugar a una sola fila con todos los landmarks\n",
    "            row = {'Image': image_file}\n",
    "            for landmark_id, landmark in enumerate(results.multi_face_landmarks[0].landmark):\n",
    "                # Añade las coordenadas x, y de cada landmark al diccionario de la fila\n",
    "                row[f'K{landmark_id + 1}X'] = landmark.x\n",
    "                row[f'K{landmark_id + 1}Y'] = landmark.y\n",
    "            \n",
    "            # Extrae el label del nombre del archivo\n",
    "            label = image_file.split('_')[1]  # Esto toma el elemento entre el primer y segundo '_'\n",
    "            if label == 'N1':  # Cambia 'N1' a 'NEUTRAL'\n",
    "                label = 'NEUTRAL'\n",
    "            row['Label'] = label\n",
    "            \n",
    "            landmarks_data.append(row)\n",
    "\n",
    "# Crea un DataFrame a partir de la lista de datos\n",
    "df_flat_landmarks = pd.DataFrame(landmarks_data)\n",
    "\n",
    "# Muestra los primeros registros del DataFrame\n",
    "print(df_flat_landmarks.head())\n",
    "\n",
    "# Opcional: Guarda el DataFrame a un archivo CSV\n",
    "# df_flat_landmarks.to_csv('flat_landmarks_images_with_label.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>K1X</th>\n",
       "      <th>K1Y</th>\n",
       "      <th>K2X</th>\n",
       "      <th>K2Y</th>\n",
       "      <th>K3X</th>\n",
       "      <th>K3Y</th>\n",
       "      <th>K4X</th>\n",
       "      <th>K4Y</th>\n",
       "      <th>K5X</th>\n",
       "      <th>...</th>\n",
       "      <th>K474Y</th>\n",
       "      <th>K475X</th>\n",
       "      <th>K475Y</th>\n",
       "      <th>K476X</th>\n",
       "      <th>K476Y</th>\n",
       "      <th>K477X</th>\n",
       "      <th>K477Y</th>\n",
       "      <th>K478X</th>\n",
       "      <th>K478Y</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame0.jpg</td>\n",
       "      <td>0.516717</td>\n",
       "      <td>0.862611</td>\n",
       "      <td>0.525122</td>\n",
       "      <td>0.781059</td>\n",
       "      <td>0.522194</td>\n",
       "      <td>0.800093</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.707113</td>\n",
       "      <td>0.527029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654642</td>\n",
       "      <td>0.597166</td>\n",
       "      <td>0.657380</td>\n",
       "      <td>0.587159</td>\n",
       "      <td>0.638631</td>\n",
       "      <td>0.575269</td>\n",
       "      <td>0.651748</td>\n",
       "      <td>0.585243</td>\n",
       "      <td>0.670582</td>\n",
       "      <td>ENOJO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame120.jpg</td>\n",
       "      <td>0.522165</td>\n",
       "      <td>0.873315</td>\n",
       "      <td>0.534889</td>\n",
       "      <td>0.798453</td>\n",
       "      <td>0.530828</td>\n",
       "      <td>0.816012</td>\n",
       "      <td>0.530545</td>\n",
       "      <td>0.722064</td>\n",
       "      <td>0.537171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667019</td>\n",
       "      <td>0.605121</td>\n",
       "      <td>0.669919</td>\n",
       "      <td>0.595619</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>0.583513</td>\n",
       "      <td>0.663937</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.683557</td>\n",
       "      <td>ENOJO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame150.jpg</td>\n",
       "      <td>0.521257</td>\n",
       "      <td>0.869050</td>\n",
       "      <td>0.532735</td>\n",
       "      <td>0.793808</td>\n",
       "      <td>0.528710</td>\n",
       "      <td>0.811547</td>\n",
       "      <td>0.528189</td>\n",
       "      <td>0.717880</td>\n",
       "      <td>0.534973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667484</td>\n",
       "      <td>0.604407</td>\n",
       "      <td>0.670765</td>\n",
       "      <td>0.594810</td>\n",
       "      <td>0.650166</td>\n",
       "      <td>0.582683</td>\n",
       "      <td>0.663929</td>\n",
       "      <td>0.592320</td>\n",
       "      <td>0.684695</td>\n",
       "      <td>ENOJO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame180.jpg</td>\n",
       "      <td>0.519951</td>\n",
       "      <td>0.869113</td>\n",
       "      <td>0.532665</td>\n",
       "      <td>0.793192</td>\n",
       "      <td>0.528782</td>\n",
       "      <td>0.810866</td>\n",
       "      <td>0.527933</td>\n",
       "      <td>0.718591</td>\n",
       "      <td>0.534852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671306</td>\n",
       "      <td>0.602347</td>\n",
       "      <td>0.674140</td>\n",
       "      <td>0.593610</td>\n",
       "      <td>0.656219</td>\n",
       "      <td>0.582534</td>\n",
       "      <td>0.668459</td>\n",
       "      <td>0.591239</td>\n",
       "      <td>0.686257</td>\n",
       "      <td>ENOJO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUJETO10_ENOJO_segmentado_frame210.jpg</td>\n",
       "      <td>0.522861</td>\n",
       "      <td>0.869178</td>\n",
       "      <td>0.534696</td>\n",
       "      <td>0.794747</td>\n",
       "      <td>0.530758</td>\n",
       "      <td>0.812396</td>\n",
       "      <td>0.530206</td>\n",
       "      <td>0.719392</td>\n",
       "      <td>0.536961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669738</td>\n",
       "      <td>0.605531</td>\n",
       "      <td>0.672815</td>\n",
       "      <td>0.596163</td>\n",
       "      <td>0.653849</td>\n",
       "      <td>0.584328</td>\n",
       "      <td>0.666554</td>\n",
       "      <td>0.593704</td>\n",
       "      <td>0.685507</td>\n",
       "      <td>ENOJO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame240.jpg</td>\n",
       "      <td>0.453008</td>\n",
       "      <td>0.793498</td>\n",
       "      <td>0.458177</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.456633</td>\n",
       "      <td>0.737436</td>\n",
       "      <td>0.452061</td>\n",
       "      <td>0.642798</td>\n",
       "      <td>0.459526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.537411</td>\n",
       "      <td>0.605893</td>\n",
       "      <td>0.526688</td>\n",
       "      <td>0.585254</td>\n",
       "      <td>0.513452</td>\n",
       "      <td>0.599915</td>\n",
       "      <td>0.524098</td>\n",
       "      <td>0.620761</td>\n",
       "      <td>TRISTEZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame270.jpg</td>\n",
       "      <td>0.455805</td>\n",
       "      <td>0.793401</td>\n",
       "      <td>0.464809</td>\n",
       "      <td>0.713732</td>\n",
       "      <td>0.463130</td>\n",
       "      <td>0.735859</td>\n",
       "      <td>0.458704</td>\n",
       "      <td>0.641522</td>\n",
       "      <td>0.466215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605918</td>\n",
       "      <td>0.544063</td>\n",
       "      <td>0.608902</td>\n",
       "      <td>0.533972</td>\n",
       "      <td>0.588991</td>\n",
       "      <td>0.521302</td>\n",
       "      <td>0.602830</td>\n",
       "      <td>0.531304</td>\n",
       "      <td>0.622859</td>\n",
       "      <td>TRISTEZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame30.jpg</td>\n",
       "      <td>0.451938</td>\n",
       "      <td>0.797064</td>\n",
       "      <td>0.454748</td>\n",
       "      <td>0.717145</td>\n",
       "      <td>0.453761</td>\n",
       "      <td>0.739351</td>\n",
       "      <td>0.448418</td>\n",
       "      <td>0.644463</td>\n",
       "      <td>0.455899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601855</td>\n",
       "      <td>0.535964</td>\n",
       "      <td>0.604622</td>\n",
       "      <td>0.524808</td>\n",
       "      <td>0.583856</td>\n",
       "      <td>0.511326</td>\n",
       "      <td>0.598940</td>\n",
       "      <td>0.522452</td>\n",
       "      <td>0.619921</td>\n",
       "      <td>TRISTEZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame60.jpg</td>\n",
       "      <td>0.463313</td>\n",
       "      <td>0.787222</td>\n",
       "      <td>0.469396</td>\n",
       "      <td>0.711167</td>\n",
       "      <td>0.467647</td>\n",
       "      <td>0.732886</td>\n",
       "      <td>0.462881</td>\n",
       "      <td>0.640404</td>\n",
       "      <td>0.470740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601218</td>\n",
       "      <td>0.547727</td>\n",
       "      <td>0.604323</td>\n",
       "      <td>0.537343</td>\n",
       "      <td>0.584747</td>\n",
       "      <td>0.523882</td>\n",
       "      <td>0.598001</td>\n",
       "      <td>0.534184</td>\n",
       "      <td>0.617750</td>\n",
       "      <td>TRISTEZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>SUJETO9_TRISTEZA_segmentado_frame90.jpg</td>\n",
       "      <td>0.466474</td>\n",
       "      <td>0.795463</td>\n",
       "      <td>0.471724</td>\n",
       "      <td>0.722081</td>\n",
       "      <td>0.469866</td>\n",
       "      <td>0.742865</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.650051</td>\n",
       "      <td>0.473138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608497</td>\n",
       "      <td>0.550433</td>\n",
       "      <td>0.611247</td>\n",
       "      <td>0.540197</td>\n",
       "      <td>0.591266</td>\n",
       "      <td>0.527597</td>\n",
       "      <td>0.605644</td>\n",
       "      <td>0.537758</td>\n",
       "      <td>0.625812</td>\n",
       "      <td>TRISTEZA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 958 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Image       K1X       K1Y       K2X  \\\n",
       "0        SUJETO10_ENOJO_segmentado_frame0.jpg  0.516717  0.862611  0.525122   \n",
       "1      SUJETO10_ENOJO_segmentado_frame120.jpg  0.522165  0.873315  0.534889   \n",
       "2      SUJETO10_ENOJO_segmentado_frame150.jpg  0.521257  0.869050  0.532735   \n",
       "3      SUJETO10_ENOJO_segmentado_frame180.jpg  0.519951  0.869113  0.532665   \n",
       "4      SUJETO10_ENOJO_segmentado_frame210.jpg  0.522861  0.869178  0.534696   \n",
       "..                                        ...       ...       ...       ...   \n",
       "464  SUJETO9_TRISTEZA_segmentado_frame240.jpg  0.453008  0.793498  0.458177   \n",
       "465  SUJETO9_TRISTEZA_segmentado_frame270.jpg  0.455805  0.793401  0.464809   \n",
       "466   SUJETO9_TRISTEZA_segmentado_frame30.jpg  0.451938  0.797064  0.454748   \n",
       "467   SUJETO9_TRISTEZA_segmentado_frame60.jpg  0.463313  0.787222  0.469396   \n",
       "468   SUJETO9_TRISTEZA_segmentado_frame90.jpg  0.466474  0.795463  0.471724   \n",
       "\n",
       "          K2Y       K3X       K3Y       K4X       K4Y       K5X  ...  \\\n",
       "0    0.781059  0.522194  0.800093  0.520307  0.707113  0.527029  ...   \n",
       "1    0.798453  0.530828  0.816012  0.530545  0.722064  0.537171  ...   \n",
       "2    0.793808  0.528710  0.811547  0.528189  0.717880  0.534973  ...   \n",
       "3    0.793192  0.528782  0.810866  0.527933  0.718591  0.534852  ...   \n",
       "4    0.794747  0.530758  0.812396  0.530206  0.719392  0.536961  ...   \n",
       "..        ...       ...       ...       ...       ...       ...  ...   \n",
       "464  0.714694  0.456633  0.737436  0.452061  0.642798  0.459526  ...   \n",
       "465  0.713732  0.463130  0.735859  0.458704  0.641522  0.466215  ...   \n",
       "466  0.717145  0.453761  0.739351  0.448418  0.644463  0.455899  ...   \n",
       "467  0.711167  0.467647  0.732886  0.462881  0.640404  0.470740  ...   \n",
       "468  0.722081  0.469866  0.742865  0.465500  0.650051  0.473138  ...   \n",
       "\n",
       "        K474Y     K475X     K475Y     K476X     K476Y     K477X     K477Y  \\\n",
       "0    0.654642  0.597166  0.657380  0.587159  0.638631  0.575269  0.651748   \n",
       "1    0.667019  0.605121  0.669919  0.595619  0.650519  0.583513  0.663937   \n",
       "2    0.667484  0.604407  0.670765  0.594810  0.650166  0.582683  0.663929   \n",
       "3    0.671306  0.602347  0.674140  0.593610  0.656219  0.582534  0.668459   \n",
       "4    0.669738  0.605531  0.672815  0.596163  0.653849  0.584328  0.666554   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "464  0.602941  0.537411  0.605893  0.526688  0.585254  0.513452  0.599915   \n",
       "465  0.605918  0.544063  0.608902  0.533972  0.588991  0.521302  0.602830   \n",
       "466  0.601855  0.535964  0.604622  0.524808  0.583856  0.511326  0.598940   \n",
       "467  0.601218  0.547727  0.604323  0.537343  0.584747  0.523882  0.598001   \n",
       "468  0.608497  0.550433  0.611247  0.540197  0.591266  0.527597  0.605644   \n",
       "\n",
       "        K478X     K478Y     Label  \n",
       "0    0.585243  0.670582     ENOJO  \n",
       "1    0.593000  0.683557     ENOJO  \n",
       "2    0.592320  0.684695     ENOJO  \n",
       "3    0.591239  0.686257     ENOJO  \n",
       "4    0.593704  0.685507     ENOJO  \n",
       "..        ...       ...       ...  \n",
       "464  0.524098  0.620761  TRISTEZA  \n",
       "465  0.531304  0.622859  TRISTEZA  \n",
       "466  0.522452  0.619921  TRISTEZA  \n",
       "467  0.534184  0.617750  TRISTEZA  \n",
       "468  0.537758  0.625812  TRISTEZA  \n",
       "\n",
       "[469 rows x 958 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flat_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcional: Guarda el DataFrame a un archivo CSV\n",
    "df_flat_landmarks.to_csv('flat_landmarks_images_with_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos a Evaluar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccionando el mejor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validaci&oacute;n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
